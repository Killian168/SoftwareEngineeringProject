{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m128\u001b[0m\n\u001b[0;31m    args = parser.parse_args()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import editdistance\n",
    "from DataLoader import DataLoader, Batch\n",
    "from Model import Model, DecoderType\n",
    "from SamplePreprocessor import preprocess\n",
    "\n",
    "# Defines all files neccessary and all their relative paths\n",
    "class FilePaths:\n",
    "\t\"filenames and paths to data\"\n",
    "\tfnCharList = '../model/charList.txt'\n",
    "\tfnAccuracy = '../model/accuracy.txt'\n",
    "\tfnTrain = '../data/'\n",
    "\tfnInfer = '../data/test.png'\n",
    "\tfnCorpus = '../data/corpus.txt'\n",
    "\n",
    "# Trains the model on the chosen dataset\n",
    "def train(model, loader):\n",
    "\t\"train NN\"\n",
    "\tepoch = 0 # Hold the number of times the NN has been trained\n",
    "\tbestCharErrorRate = float('inf') # Holds the best error rate\n",
    "\tnoImprovementSince = 0 # Holds the number of epochs since last improvement\n",
    "\tearlyStopping = 10 # Stop training after this many epochs have been reached with no improvement\n",
    "\twhile True:\n",
    "\t\tepoch += 1\n",
    "\t\tprint('Epoch:', epoch)\n",
    "\n",
    "\t\t# Actually train the algorithm\n",
    "\t\tprint('Train NN')\n",
    "\t\tloader.trainSet()\n",
    "\n",
    "\t\t# Iterates throught the dataset until there is none left\n",
    "\t\t# Each iteration provides a loss that is backproped throughout the\n",
    "\t\t# System\n",
    "\t\twhile loader.hasNext():\n",
    "\t\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\t\tbatch = loader.getNext()\n",
    "\t\t\tloss = model.trainBatch(batch)\n",
    "\t\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1], 'Loss:', loss)\n",
    "\n",
    "\t\t# Validate the model\n",
    "\t\tcharErrorRate = validate(model, loader)\n",
    "\t\t\n",
    "\t\t# If it is the best validation accuracy so far then save the params\n",
    "\t\tif charErrorRate < bestCharErrorRate:\n",
    "\t\t\tprint('Character error rate improved, save model')\n",
    "\t\t\tbestCharErrorRate = charErrorRate # Set bestCharErrorRate for future comparisions\n",
    "\t\t\tnoImprovementSince = 0 # Reset to 0\n",
    "\t\t\tmodel.save() # Save the current model\n",
    "\t\t\topen(FilePaths.fnAccuracy, 'w').write('Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
    "\t\telse:\n",
    "\t\t\tprint('Character error rate not improved')\n",
    "\t\t\tnoImprovementSince += 1\n",
    "\n",
    "\t\t# Stop training If there has been no improvements in the last 10 epochs\n",
    "\t\tif noImprovementSince >= earlyStopping:\n",
    "\t\t\tprint('No more improvement since %d epochs. Training stopped.' % earlyStopping)\n",
    "\t\t\tbreak\n",
    "\n",
    "# Validates the model after a round of training\n",
    "def validate(model, loader):\n",
    "\tprint('Validate NN')\n",
    "\tloader.validationSet()\n",
    "\t\n",
    "\t# Init all to 0\n",
    "\tnumCharErr = 0\n",
    "\tnumCharTotal = 0\n",
    "\tnumWordOK = 0\n",
    "\tnumWordTotal = 0\n",
    "\n",
    "\t# Main loop to validate against truth\n",
    "\twhile loader.hasNext():\n",
    "    \t\n",
    "\t\t# Gets next batch\n",
    "\t\titerInfo = loader.getIteratorInfo()\n",
    "\t\tprint('Batch:', iterInfo[0],'/', iterInfo[1])\n",
    "\t\tbatch = loader.getNext()\n",
    "\t\trecognized = model.inferBatch(batch)\n",
    "\t\t\n",
    "\t\t# If the word is recognised or not\n",
    "\t\tprint('Ground truth -> Recognized')\t\n",
    "\t\tfor i in range(len(recognized)):\n",
    "\t\t\tnumWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
    "\t\t\tnumWordTotal += 1\n",
    "\t\t\tdist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
    "\t\t\tnumCharErr += dist\n",
    "\t\t\tnumCharTotal += len(batch.gtTexts[i])\n",
    "\t\t\tprint('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
    "\t\n",
    "\t# print validation result\n",
    "\tcharErrorRate = numCharErr / numCharTotal\n",
    "\twordAccuracy = numWordOK / numWordTotal\n",
    "\tprint('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
    "\treturn charErrorRate\n",
    "\n",
    "\n",
    "def infer(model, fnImg):\n",
    "\t\"recognize text in image provided by file path\"\n",
    "\timg = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n",
    "\tbatch = Batch(None, [img] * Model.batchSize) # fill all batch elements with same input image\n",
    "\trecognized = model.inferBatch(batch) # recognize text\n",
    "\tprint('Recognized:', '\"' + recognized[0] + '\"') # all batch elements hold same result\n",
    "\n",
    "\n",
    "# Main function for the program\n",
    "def main():\n",
    "\t\"main function\"\n",
    "    \n",
    "\t# Command line args for control of the program\n",
    "\tparser = argparse.ArgumentParser()\n",
    "    \n",
    "\t# Train the algorithm\n",
    "\tparser.add_argument(\"--train\", help=\"train the NN\", action=\"store_true\")\n",
    "    \n",
    "\t# Validate the algorithm as is against the test dataset\n",
    "\tparser.add_argument(\"--validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "    \n",
    "\t# Use beamsearch add on for better accuracy\n",
    "\tparser.add_argument(\"--beamsearch\", help=\"use beam search instead of best path decoding\", action=\"store_true\")\n",
    "    \n",
    "\t# Use wordbeamsearch for better accuracy on words\n",
    "\tparser.add_argument(\"--wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\t# If either beamsearch or wordbeamsearch set to that decoder\n",
    "\tdecoderType = DecoderType.BestPath\n",
    "\tif args.beamsearch:\n",
    "\t\tdecoderType = DecoderType.BeamSearch\n",
    "\telif args.wordbeamsearch:\n",
    "\t\tdecoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "\t# If args is train or validate on IAM dataset\n",
    "\tif args.train or args.validate:\n",
    "\t\t# Load training data, create TF model\n",
    "\t\tloader = DataLoader(FilePaths.fnTrain, Model.batchSize, Model.imgSize, Model.maxTextLen)\n",
    "\n",
    "\t\t# Save characters of model for inference mode\n",
    "\t\topen(FilePaths.fnCharList, 'w').write(str().join(loader.charList))\n",
    "\t\t\n",
    "\t\t# Save words contained in dataset into file\n",
    "\t\topen(FilePaths.fnCorpus, 'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "        # Execute training or validation\n",
    "\t\tif args.train:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType)\n",
    "\t\t\ttrain(model, loader)\n",
    "\t\telif args.validate:\n",
    "\t\t\tmodel = Model(loader.charList, decoderType, mustRestore=True)\n",
    "\t\t\tvalidate(model, loader)\n",
    "\n",
    "\t# Infer text on test image\n",
    "\telse:\n",
    "\t\tprint(open(FilePaths.fnAccuracy).read())\n",
    "\t\tmodel = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=True)\n",
    "\t\tinfer(model, FilePaths.fnInfer)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
